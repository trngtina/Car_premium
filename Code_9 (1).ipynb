{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    91278\n",
      "1    13905\n",
      "2     2190\n",
      "3      482\n",
      "4       87\n",
      "5       35\n",
      "6       17\n",
      "7        5\n",
      "8        1\n",
      "Name: claimNumber, dtype: int64\n",
      "        gender carType carCategory     occupation  age  carGroup  bonus  \\\n",
      "0       Female       D       Small       Employed   23        19    120   \n",
      "1         Male       E       Small     Unemployed   26         1     30   \n",
      "3         Male       A       Small  Self-employed   30         1    -40   \n",
      "4         Male       B       Small  Self-employed   35         1     60   \n",
      "5       Female       D       Small       Employed   40         8     50   \n",
      "...        ...     ...         ...            ...  ...       ...    ...   \n",
      "119995    Male       D      Medium  Self-employed   39        12    -30   \n",
      "119996    Male       E       Large        Retired   61         2     10   \n",
      "119997    Male       C      Medium     Unemployed   37        20    130   \n",
      "119998    Male       A      Medium        Retired   46        17    -10   \n",
      "119999    Male       B      Medium       Employed   20        13     20   \n",
      "\n",
      "        carValue  material subRegion region  cityDensity  exposure  \\\n",
      "0          15090         1       T11      T    28.615596       365   \n",
      "1          14235         1       U15      U    59.403785       365   \n",
      "3           9395         0       Q34      Q   212.424705       365   \n",
      "4           6030         1        R3      R   200.656550       365   \n",
      "5          25725         0       L55      L    91.550641       365   \n",
      "...          ...       ...       ...    ...          ...       ...   \n",
      "119995     19565         0       R11      R   259.004060       365   \n",
      "119996     25545         1        M3      M   141.036868       365   \n",
      "119997     16490         0       Q66      Q    99.436211       194   \n",
      "119998     26480         1        S7      S    32.570691        91   \n",
      "119999      3550         0       L27      L    58.819868       365   \n",
      "\n",
      "        claimNumber   claimValue  \n",
      "0                 1  3105.572905  \n",
      "1                 0     0.000000  \n",
      "3                 0     0.000000  \n",
      "4                 0     0.000000  \n",
      "5                 0     0.000000  \n",
      "...             ...          ...  \n",
      "119995            0     0.000000  \n",
      "119996            0     0.000000  \n",
      "119997            0     0.000000  \n",
      "119998            0     0.000000  \n",
      "119999            0     0.000000  \n",
      "\n",
      "[108000 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "dataTrain = pd.concat([pd.read_csv(\"dataTrain_9.csv\"),pd.read_csv(\"dataTrain_24.csv\")], ignore_index=True)\n",
    "\n",
    "dataTrain = dataTrain.drop(dataTrain[dataTrain.age > 75].index)\n",
    "dataTrain = dataTrain.drop(dataTrain[dataTrain.carValue > 50000].index)\n",
    "dataTrain = dataTrain.drop(dataTrain[dataTrain.exposure < 90 ].index)\n",
    "\n",
    "print(dataTrain['claimNumber'].value_counts())\n",
    "\n",
    "for col_name in [\"gender\", \"carType\",\"carCategory\", \"occupation\", \"carGroup\",\"subRegion\",\"region\"]:\n",
    "    if(dataTrain[col_name].dtype == 'object'):\n",
    "        dataTrain[col_name]= dataTrain[col_name].astype('category')\n",
    "\n",
    "dataTrain = dataTrain.drop(columns='id')\n",
    "print(dataTrain)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "columnsToEncode = list(dataTrain.select_dtypes(include=['category','object']))\n",
    "\n",
    "for feature in columnsToEncode:\n",
    "    # Get one hot encoding of columns B\n",
    "    one_hot = pd.get_dummies(dataTrain[feature])\n",
    "# Drop column B as it is now encoded\n",
    "    dataTrain = dataTrain.drop(feature,axis = 1)\n",
    "# Join the encoded df\n",
    "    dataTrain = dataTrain.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataTrain.loc[:, (dataTrain.columns != \"claimValue\") & (dataTrain.columns != \"claimNumber\") & (dataTrain.columns != \"Female\")]\n",
    "\n",
    "y_freq = dataTrain[\"claimNumber\"]\n",
    "y_severity = dataTrain[\"claimValue\"]\n",
    "    # First Stratification because the dataset is imbalanced\n",
    "\n",
    "X_train, X_test, y_train_freq, y_test_freq = train_test_split(X, y_freq, \n",
    "#stratify=y_freq, \n",
    "test_size = 0.000001, random_state = 41)\n",
    "X_train, X_test, y_train_severity, y_test_severity = train_test_split(X, y_severity, \n",
    "# stratify=y_freq, \n",
    "test_size = 0.000001, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering on X_train and y_train to help model\n",
    "\n",
    "    # Assembling X_train and y_train\n",
    "\n",
    "X_train = pd.concat([X_train, y_train_freq, y_train_severity], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/vvd1q9td5wx3hwy02b2qvb0r0000gn/T/ipykernel_71962/2298949668.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['claimNumber'][X_train['claimNumber'] > 0] = 1\n"
     ]
    }
   ],
   "source": [
    "# Multiplying according to y_train (=claimNumber)\n",
    "\n",
    "## Faire une maille plus grande (feature engineering)\n",
    "\n",
    "X_train = X_train.loc[X_train[\"claimNumber\"]==0].append(X_train.loc[X_train.index.repeat(X_train.claimNumber)], ignore_index = True)\n",
    "\n",
    "X_train['claimNumber'][X_train['claimNumber'] > 0] = 1\n",
    "\n",
    "# Remelanger la base Train car index.repeat a classe les individus par leur claimNumber\n",
    "\n",
    "X_train = X_train.sample(frac = 1)\n",
    "\n",
    "    # Dissociate X_train and y_train\n",
    "y_train_freq = X_train[\"claimNumber\"]\n",
    "y_train_severity = X_train[\"claimValue\"]\n",
    "weight_train = X_train[\"exposure\"]\n",
    "X_train = X_train.loc[:, (X_train.columns != \"claimNumber\") & (X_train.columns != \"claimValue\") & (X_train.columns != \"exposure\")]\n",
    "\n",
    "# Changing y_test\n",
    "\n",
    "y_test_freq[y_test_freq > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 7}, max_depth=30,\n",
       "                       max_features=0.8, min_samples_leaf=4, n_estimators=300,\n",
       "                       n_jobs=4, warm_start=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(max_features=5, n_estimators=100)\n",
    "# rf = RandomForestClassifier(n_estimators=100, class_weight = \"balanced\", max_depth=15, max_features=0.6, min_samples_leaf = 7)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300,class_weight = {0: 1, 1: 7}, max_depth=30, max_features=0.8, min_samples_leaf = 4, warm_start = True, n_jobs = 4)\n",
    "\n",
    "rf.fit(X_train, y_train_freq, sample_weight=weight_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/vvd1q9td5wx3hwy02b2qvb0r0000gn/T/ipykernel_71962/2682224860.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[\"prob\"] = rf.predict_proba(X_test.loc[:, (X_test.columns != \"exposure\")])[:,1]\n"
     ]
    }
   ],
   "source": [
    "X_train[\"prob\"] = rf.predict_proba(X_train)[:,1]\n",
    "X_test[\"prob\"] = rf.predict_proba(X_test.loc[:, (X_test.columns != \"exposure\")])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, max_features=0.8, max_samples=0.9,\n",
       "                      n_estimators=110, n_jobs=4, warm_start=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression\n",
    "\n",
    "rfreg = RandomForestRegressor(n_estimators = 110, warm_start = True, max_depth = 20, \n",
    "max_features=0.8, max_samples=0.9,\n",
    "n_jobs = 4)\n",
    "\n",
    "rfreg.fit(X_train, y_train_severity, sample_weight = weight_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Done with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on the dataTest set\n",
    "\n",
    "dataTest = pd.read_csv(\"test.csv\")\n",
    "for col_name in [\"gender\", \"carType\",\"carCategory\", \"occupation\", \"carGroup\",\"subRegion\",\"region\"]:\n",
    "    if(dataTest[col_name].dtype == 'object'):\n",
    "        dataTest[col_name]= dataTest[col_name].astype('category')\n",
    "\n",
    "dataTest = dataTest.drop(columns='id')\n",
    "\n",
    "columnsToEncode = list(dataTest.select_dtypes(include=['category','object']))\n",
    "categories = []\n",
    "\n",
    "for feature in columnsToEncode:\n",
    "    # Get one hot encoding of columns B\n",
    "    one_hot = pd.get_dummies(dataTest[feature])\n",
    "# Drop column B as it is now encoded\n",
    "    dataTest = dataTest.drop(feature,axis = 1)\n",
    "# Join the encoded df\n",
    "    dataTest = dataTest.join(one_hot)\n",
    "    categories = categories + list(one_hot.columns)\n",
    "\n",
    "X_ = dataTest.loc[:, (dataTest.columns != \"Female\")]\n",
    "\n",
    "# Make predictions with probability estimates\n",
    "probs_test = rf.predict_proba(X_)\n",
    "\n",
    "X_['prob'] = probs_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the premium\n",
    "\n",
    "premium = rfreg.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425.9347474183762\n"
     ]
    }
   ],
   "source": [
    "# Adjusting the premium \n",
    "\n",
    "# print(len(premium))\n",
    "\n",
    "# print(sum(premium)/len(premium))\n",
    "\n",
    "premium[premium < 200] = 210\n",
    "\n",
    "# print(sum(premium)/len(premium))\n",
    "\n",
    "premium[(premium > 400)&(premium < 600)] += 50\n",
    "\n",
    "# print(sum(premium)/len(premium))\n",
    "\n",
    "premium[premium < 800] += 30\n",
    "\n",
    "# print(sum(premium)/len(premium))\n",
    "\n",
    "premium += 70\n",
    "\n",
    "print(sum(premium)/len(premium))\n",
    "#premium = premium + 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "premium = pd.DataFrame(premium)\n",
    "premium.rename(columns = {0:'premium'}, inplace = True)\n",
    "premium.index += 1\n",
    "premium.to_csv(r'/Users/tina/Desktop/Projet Data Science/premium_9.csv', index=True, header=True, index_label='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23533c75c6b21c8bdd5a2db9fdb278f077589470e09160bf39f6c065a121a787"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
